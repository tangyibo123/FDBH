model_params:
  name: 'Hash_Contra_IR'
  img_size: 32
  in_channels: 3
  latent_dim: 48
  learnable_parameter_dim: 48
  gamma: 10.0
  max_capacity: 25
  Capacity_max_iter: 10000 
  hypermeter: [1, 0, 1, 1, 0.5]
  backbone : Cifar_AE
  path :  './logs/test_lantent_z/CIFAR10Pair_AE_[1, 0.1]64_model.ckpt'
  
exp_params:
  ckpt_path: './logs/test_lantent_z/CIFAR10Pair_Paired_Transform[1, 0, 1, 1, 0.5]64_model.ckpt'
  dataset: CIFAR10Pair
  data_path: "/home/bbct/wangfan/dataset/" 
  img_size: 32
  batch_size: 512 # Better to have a square number 
  LR: 0.0005
  momentum : 0.9
  weight_decay: 0.0
  #scheduler_gamma: 0.95
  
  #LR: 0.05
  #weight_decay: 0.0001
  #scheduler_gamma: 0.95
  num_epochs: 200
trainer_params:
  gpus: 1
  distributed_backend: 'dp'
  num_nodes: 1
  max_nb_epochs: 200
  max_epochs: 200
  epochs: 200

logging_params:
  save_dir: "logs/"
  name: "Cifar_48_0_299"
  #name: "Use_Pretrained_AE"
  #"Hash_Contra_IR_NoneRelu_0_299"
  manual_seed: 1265
